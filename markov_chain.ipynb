{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho final de Sistemas Baseados em Conhecimento\n",
    "### Tema: Geração de texto com Markov\n",
    "### Alunos: Caio Lucas da Silva Chacon (20200025769) e Jonas Gabriel Leite de Araújo (20200007608)\n",
    "\n",
    "### Dado o início do texto em português, gerar automaticamente algo que faça sentido usando cadeias de Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom casmurro capítulo primeiro do título uma noite destas vindo da cidade para o engenho novo encont\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "import numpy as np\n",
    "import re\n",
    "from random import random \n",
    "\n",
    "# Leitura do arquivo e processamento textual para melhor análise\n",
    "\n",
    "def read_text(filename):\n",
    "    \"\"\"\"\n",
    "    Função que lê um arquivo de texto e retorna o conteúdo em minúsculas\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'r', encoding=\"utf8\") as file:\n",
    "        content = file.read().lower()\n",
    "\n",
    "        content = re.sub(r'[\\n,\\.;:\\\"\\'_\\-\\t\\—]', ' ', content)\n",
    "        content = re.sub(r'\\s+', ' ', content)\n",
    "\n",
    "    return content\n",
    "\n",
    "content = read_text('domCasmurro.txt')\n",
    "print(content[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(corpus):\n",
    "    \"\"\"\n",
    "    Retorna todas as palavras\n",
    "    \"\"\"\n",
    "    corpus_words = corpus.split(' ')\n",
    "    corpus_words= [word for word in corpus_words if word != '']\n",
    "    corpus_words # [...'a', 'wyvern', ',', 'two', 'of', 'the', 'thousand'...]\n",
    "    return corpus_words # 2185920\n",
    "\n",
    "def get_distinct_words_count(corpus_words):\n",
    "    \"\"\"\n",
    "    Função que retorna a quantidade de palavras distintas e um dicionário com o índice de cada palavra\n",
    "    \"\"\"\n",
    "\n",
    "    distinct_words = list(set(corpus_words))\n",
    "    word_idx_dict = {word: i for i, word in enumerate(distinct_words)}\n",
    "    distinct_words_count = len(list(set(corpus_words)))\n",
    " \n",
    "    return distinct_words_count, word_idx_dict # 32663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição da probabilidade inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de palavras distintas:  9129\n",
      "ID da palavra capitu:  5751\n",
      "Probabilidade da palavra capitu:  0.004921245119889907\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus_words = get_words(content)\n",
    "\n",
    "distinct_words = list(set(corpus_words))\n",
    "distinct_words_count, word_idx_dict = get_distinct_words_count(corpus_words)\n",
    "\n",
    "counter_corpus = Counter(corpus_words)\n",
    "\n",
    "# probabilidade de cada palavra dividido pela quantidade de palavras no corpus\n",
    "distinct_words_prob = {word: counter_corpus[word]/len(corpus_words) for word in distinct_words}\n",
    "\n",
    "print(\"Contagem de palavras distintas: \", distinct_words_count)\n",
    "print(\"ID da palavra capitu: \", word_idx_dict['capitu'])\n",
    "print(\"Probabilidade da palavra capitu: \", distinct_words_prob['capitu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dom casmurro', 'casmurro capítulo', 'capítulo primeiro', 'primeiro do', 'do título', 'título uma', 'uma noite', 'noite destas', 'destas vindo', 'vindo da']\n"
     ]
    }
   ],
   "source": [
    "n_grams = 2 # Numero de palavras anteriores para prever a próxima\n",
    "# Criação de conjuntos de palavras de tamanho n_grams\n",
    "sets_of_n_words = [ ' '.join(corpus_words[i:i+n_grams]) for i, _ in enumerate(corpus_words[:-n_grams]) ]\n",
    "len_n_words = len(list(set(sets_of_n_words)))\n",
    "\n",
    "print(sets_of_n_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da matriz de transição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(indice_N-grama, indice_proxima_palavra) = qtd_ocorrencias\n",
      "  (1, 1373)\t1.0\n",
      "  (4, 7168)\t1.0\n",
      "  (0, 2468)\t1.0\n",
      "  (0, 1268)\t1.0\n",
      "  (9, 7446)\t1.0\n",
      "  (5, 8236)\t1.0\n",
      "  (4, 5842)\t1.0\n",
      "  (8, 7451)\t1.0\n",
      "  (2, 8598)\t1.0\n",
      "  (7, 2023)\t1.0\n",
      "  (6, 6831)\t1.0\n",
      "  (4, 638)\t1.0\n",
      "  (3, 7003)\t1.0\n",
      "  (4, 4212)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Inicialização de uma matriz esparsa com tamanho len_n_words, distincit_words_count\n",
    "# para armazenar a contagem de palavras\n",
    "n_grams_frequency_matrix = dok_matrix((len_n_words, distinct_words_count))\n",
    "\n",
    "# Criação de um dicionário para mapear os conjuntos de palavras para índices\n",
    "distinct_sets_of_n_words = list(set(sets_of_n_words))\n",
    "\n",
    "# Indice pra cada n_gram\n",
    "n_gram_idx_dict = {word: i for i, word in enumerate(distinct_sets_of_n_words)}\n",
    "\n",
    "# Preenchimento da matriz com as contagens\n",
    "for i, word in enumerate(sets_of_n_words[:-n_grams]): # Percorre todos os bigramas\n",
    "    # Linha da matriz\n",
    "    n_gram_idx = n_gram_idx_dict[word] # Indice do n_gram\n",
    "    # Coluna da matriz\n",
    "    next_word_idx = word_idx_dict[corpus_words[i+n_grams]] # Palavra que aparece logo após o n_grama\n",
    "    \n",
    "    # Preenchimento da matriz com a quantidade de vezes que o bigrama ocorre\n",
    "    n_grams_frequency_matrix[n_gram_idx, next_word_idx] += 1\n",
    "    \n",
    "print(\"(indice_N-grama, indice_proxima_palavra) = qtd_ocorrencias\")\n",
    "print(n_grams_frequency_matrix[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_choice(weights_array, distinct_words):\n",
    "    \"\"\" \n",
    "    Função que retorna um elemento aleatório da sequência de 'objetos',\n",
    "    a probabilidade dos objetos é ponderada de acordo com a porcentagem.\n",
    "    \"\"\"\n",
    "    sum_of_weights = weights_array.sum() # A soma vai ser sempre igual a 1\n",
    "    # standardization:\n",
    "    np.multiply(weights_array, 1000 / sum_of_weights, weights_array)\n",
    "    weights_array = weights_array.cumsum()\n",
    "    # print(\"Pesos acumulados\", weights_array)\n",
    "    x = random()\n",
    "    # print(\"Número aleatório\", x)\n",
    "\n",
    "    for i in range(len(weights_array)): # len(weights_array) = len(distinct_words)\n",
    "        if x < weights_array[i]: # Se o número aleatório for menor que a probabilidade acumulada\n",
    "            return distinct_words[i]\n",
    "        \n",
    "def get_next_word(word_sequence):\n",
    "    \"\"\"\n",
    "    Função que retorna a próxima palavra após a sequência de palavras\n",
    "    \"\"\"\n",
    "    next_word_vector = n_grams_frequency_matrix[n_gram_idx_dict[word_sequence]] # Linha do bigrama\n",
    "    next_word_probability = next_word_vector/next_word_vector.sum()\n",
    "\n",
    "    next_word = weighted_choice(next_word_probability.toarray(), distinct_words)\n",
    "    \n",
    "    # print(\"Probabilidade da próxima palavra\" , next_word_probability.toarray())\n",
    "    # print(\"Próxima palavra\" , next_word)    \n",
    "    return next_word\n",
    "    \n",
    "def markov_chain(initial_text, chain_length=30):\n",
    "    \"\"\"\n",
    "    Função que gera um texto de acordo com o texto inicial\n",
    "    \"\"\"\n",
    "    current_words = initial_text.split(' ')\n",
    "    sentence = initial_text\n",
    "\n",
    "    for _ in range(chain_length):\n",
    "        sentence += ' '\n",
    "        next_word = get_next_word(' '.join(current_words))\n",
    "        sentence += next_word\n",
    "        current_words = current_words[1:] + [next_word]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dom casmurro o receio é que há tais semelhanças inexplicáveis pelo dia adiante e apagou o escrito pádua saiu ao quintal mas as honras dele tio cosme entrou a batê las de um cavaleiro um dandi como então dizíamos montava um belo cavalo alazão firme na cabeça assim me replicou capitu e'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_chain('dom casmurro', chain_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'capitu não achava tratava se de mim mesmo capítulo verteu ela umas lágrimas que enxugou sem explicar e os olhos dele expliquei nem eu digo vem amanhã sancha não tirava os olhos dele expliquei nem eu digo vem amanhã sancha não tirava os olhos dele expliquei nem eu digo vem amanhã sancha'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_chain('capitu não', chain_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agora que tudo é claro que só há de pagar a dívida contraída outra moeda que valesse tanto ou mais casos estranhos falta me tempo pelo que não digo nada depois da partida sancha quis despedir se dela fique josé dias corrigiu a alegria não tem ambição a separação é indispensável e'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_chain('agora que', chain_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(initial_text, n_grams_frequency_matrix, distinct_sets_of_n_words, word_idx_dict, n_grams=1, num_words=100):\n",
    "    # Quebrar o texto inicial em n-grams\n",
    "    initial_n_grams = initial_text.split()\n",
    "    \n",
    "    # Convertendo a matriz dok para uma matriz densa\n",
    "    transition_probabilities = n_grams_frequency_matrix.toarray()\n",
    "    \n",
    "    # Algoritmo de Viterbi\n",
    "    sequence = initial_n_grams\n",
    "    for _ in range(num_words):\n",
    "        current_state = sequence[-n_grams:]\n",
    "        current_state_idx = distinct_sets_of_n_words.index(' '.join(current_state))\n",
    "        #print(current_state_idx)\n",
    "        \n",
    "        # Calcular as probabilidades de transição para o próximo estado\n",
    "        next_state_probs = transition_probabilities[current_state_idx]\n",
    "        #print(next_state_probs)\n",
    "        \n",
    "        # Escolher o próximo estado baseado na probabilidade\n",
    "        next_state_idx = np.argmax(next_state_probs)\n",
    "        #print(next_state_idx)\n",
    "        next_state = distinct_words[next_state_idx].split()[0]\n",
    "        \n",
    "        # Adicionar a próxima palavra à sequência\n",
    "        sequence.append(next_state)\n",
    "    \n",
    "    return ' '.join(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'capitu refletiu algum tempo e acabou perguntando me se lhe disserem que pode aprender na escola de medicina o ônibus parou e o resto do mundo o que é que não era ainda melhor haver gemido somente sem as saudades confessadas os louvores como um tributo usual cara morta sem agradecimentos o'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi(\"capitu refletiu\", n_grams_frequency_matrix, distinct_sets_of_n_words, word_idx_dict, n_grams=n_grams, num_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
